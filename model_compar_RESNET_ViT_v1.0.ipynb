import torch
import torchvision.models as models
from torchvision import transforms, datasets
from torch.utils.data import DataLoader, random_split
from transformers import ViTForImageClassification, ViTImageProcessor
from tqdm import tqdm
from sklearn.metrics import accuracy_score, classification_report
import os

# 1. Caminho base do dataset (agora a raiz, sem "images")

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

base_data_path = '/content/drive/My Drive/AffectNet'

print(f'  Caminho Base do Google Drive: {base_data_path}')

# Listando tudo recursivamente

# trecho comentado - tirar o comentário somente para debug

for pasta_atual, subpastas, arquivos in os.walk(base_data_path):
    print(f'Pasta: {pasta_atual}')
    for subpasta in subpastas:
        print(f'  Subpasta: {subpasta}')
    for arquivo in arquivos:
        print(f'  Arquivo: {arquivo}')


# 2. Transformações
img_size = 224
batch_size = 32

transform = transforms.Compose([
    transforms.Resize((img_size, img_size)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])
